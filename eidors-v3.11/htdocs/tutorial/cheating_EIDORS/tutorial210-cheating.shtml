

<!DOCTYPE doctype PUBLIC "-//w3c//dtd html 4.0 transitional//en">
<html>
   <head>
<title>EIDORS</title>
   <style type="text/css">
        body, td, th {
        font-family: Verdana, Helvetica, Arial, sans-serif;
        font-size:80%;
        }
        pre, tt {
        font-family:lucida console, FixedSys, Courier, Terminal, monospaced;
        font-size:100%;
        }
        pre {
        background-color: #E0F0FE;
        border-style: groove;
        border-color: black;
        border-width: 2px;
        }
   </style>

</head>

<body link="#800000"
      marginwidth=5 marginheight=5 topmargin=5 leftmargin=5 
      vlink="#400000" >
<table border="0" cellspacing="0" cellpadding="0">
<tr height="80"><td valign="middle">
<a href="http://www.eidors.org">
<img alt="Eidors-logo" src="../../eidors-logo.jpg"></a>&nbsp;&nbsp;&nbsp;&nbsp;
</td><td>
<h2>
    EIDORS:
    <small><i>Electrical Impedance Tomography and
    Diffuse Optical Tomography Reconstruction Software</i></small>
</h2>
</td></tr></table>
<table border="0"> <tr>
<td valign="top" width="100">
<a href="http://eidors3d.sf.net/" >EIDORS</a>
(<a href="http://www.sce.carleton.ca/faculty/adler/eidors/index.shtml"
    >mirror</a>)<br>
<a href="../../index.shtml"
>Main</a><br>
<a href="../../docs.shtml"
   >Documentation</a><br>
<a href="../../tutorial/tutorial.shtml"
   >Tutorials</a><br>

<a href="../../tutorial/image_reconst.shtml"
      >&minus; Image Reconst</a><br>
<a href="../../tutorial/data_structures.shtml"
      >&minus; Data Structures</a><br>
<a href="../../tutorial/application_examples.shtml"
      >&minus; Applications</a><br>
<a href="../../tutorial/netgen.shtml"
      >&minus; FEM Modelling</a><br>
<a href="../../tutorial/GREIT.shtml"
      >&minus; GREIT</a><br>
<a href="../../tutorial/old-tutorials.shtml"
      >&minus; Old tutorials</a><br>
<a href="../../tutorial/workshop/workshop.shtml"
      >&minus; <i>Workshop</i></a><br>

<a href="../../download.shtml"
   >Download</a><br>
<a href="../../data_contrib.shtml"
   >Contrib Data</a><br>
<a href="../../GREIT/index.shtml"
   >GREIT</a><br>
<a href="../../doc/index.html"
   >Browse Docs</a><br>
<a href="https://sourceforge.net/p/eidors3d/code/HEAD/tree/trunk/"
   >Browse SVN</a><br>
<hr>
<a href="../../news.shtml">News</a><br>
<a href="https://lists.sourceforge.net/lists/listinfo/eidors3d-help"
   >Mailing list</a><br>
(<a href="https://sourceforge.net/mailarchive/forum.php?forum_name=eidors3d-help"
   >archive</a>)<br>
<a href="../../faq.shtml">FAQ</a><br>
<a href="../../programming/programming.shtml">Developer</a><br>



&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
<!-- EIDORS Navigation sidebar
     $Id: nav-sidebar.shtml 6533 2022-12-31 00:53:54Z aadler $
  -->
<p>&nbsp;
<p>
<small>Hosted by</small><br>
<a  href="http://sourceforge.net/projects/eidors3d">
   <img src="http://sourceforge.net/sflogo.php?group_id=100454&type=4"
         border="0" alt="SourceForge.net Logo"  />
</a>
</td><td>&nbsp;</td><td valign="top">




<H2>Cheating with EIDORS</H2>

<center>
Andy Adler, William R.B. Lionheart
</center><p>

In this tutorial, we try to point out some
simple approaches that work with common, linear
regularization techniques. As the solution
strategy becomes more complex, then clearly there
become more advanced ways to cheat.

<h3>
Sample Problem: The happy transform
</h3>
To motivate the problem, assume that EIT measurement
data have been acquired from an image which resembles
a 'sad' face. Being of an optimistic outlook, we wish
that the image reconstructed represent a 'happy' face
instead. Fig. 1 illustrates this 'happy transform'.

<center>
<img height="128" src="tutorial210-sad.png" align="middle"> 
<font size="+4"><b>&rarr;</b></font>
<img height="128" src="tutorial210-happy.png" align="Middle"> 
<br>
<b>Fig. 1:</b>
The <i>happy transform</i>
</center><p>

<H3>
EIDORS Setup
</H3>

<p>
To configure EIDORS, we use the following code in Matlab.
Images are shown dark on a light background, so we set
the colours as follows:

<pre width="50">
&gt;&gt; run /path/to/eidors/startup.m
&gt;&gt; calc_colours('backgnd',[1,1,1])
&gt;&gt; calc_colours('greylev',.01);
</pre>

In order to simulate data for these images, we use
the following code for a small (256 element) face model:
<pre>% Define Face Shapes: Small Face
% $Id: tutorial210a.m 1535 2008-07-26 15:36:27Z aadler $

clear p;
p.leye=   [78,97,98,117,118,141];
p.reye=   [66,82,83,102,103,123];
p.rsmile= [40:41, 53:55, 69:71, 86:88];
p.lsmile= [43:44, 57:59, 73:75, 91:93];
p.lsad =  [31,43,58,57,74,73,92,93,113,112,135];
p.rsad =  [28,40,53,54,69,87,70,107,88,108,129];
p.eyes= [p.leye,p.reye];
p.sad = [p.lsad,p.rsad];
p.smile= [p.rsmile, p.lsmile];
small_face = p;

% Simulate data for small face
imdl= mk_common_model('b2c');
e= size(imdl.fwd_model.elems,1);
simg= eidors_obj('image','small face');
simg.fwd_model= imdl.fwd_model;

% homogeneous data
simg.elem_data= ones(e,1);
vh= fwd_solve( simg);

% inhomogeneous data for sad face model
simg.elem_data(small_face.eyes)= 2;
simg.elem_data(small_face.sad)=  1.5;
vi= fwd_solve( simg);
</pre>
and for a larger (576 element) face model:
<pre>% Define Face Shapes: Large Face
% $Id: tutorial210b.m 1535 2008-07-26 15:36:27Z aadler $

clear p;
p.sad=  [ ...
     53; 57; 69; 73; 86; 87; 91; 92; 106; 107; 111; 112; 127; 128;
    129; 133; 134; 135; 147; 151; 152; 153; 157; 158; 159; 165;
    171; 172; 177; 178; 179; 184; 185; 186; 192; 193; 199; 200;
    205; 206; 207; 212; 213; 214; 220; 221; 227; 228; 229; 235;
    236; 243; 244; 251; 252; 253; 259; 260; 261; 267; 268; 275;
    276; 283; 284; 285; 292; 293; 301; 310; 319; 320]; 

p.happy= [ ...
    69; 70; 71; 73; 74; 75; 86; 87; 88; 89; 91; 92; 93; 94; 106;
   107; 108; 109; 111; 112; 113; 114; 127; 128; 129; 130; 131; 133;
   134; 135; 136; 137; 147; 151; 152; 153; 154; 155; 157; 158; 159;
   160; 161; 165; 171; 172; 176; 177; 178; 179; 180; 183; 184; 185;
   186; 187; 192; 193; 199; 200; 220; 221; 227; 228; 229; 251; 252;
   253; 259; 260; 261; 283; 284; 285; 292; 293; 319; 320]; 

p.halfy= [ ...
    57; 69; 70; 71; 73; 86; 87; 88; 89; 91; 92; 106; 107; 108; 109;
   111; 112; 127; 128; 129; 130; 131; 133; 134; 135; 147; 151; 152;
   153; 154; 155; 157; 158; 159; 165; 171; 172; 176; 177; 178; 179;
   180; 184; 185; 186; 192; 193; 199; 200; 212; 213; 214; 220; 221;
   227; 228; 229; 243; 244; 251; 252; 253; 259; 260; 261; 275; 276;
   283; 284; 285; 292; 293; 310; 319; 320];

large_face= p;
</pre>

<h3>
Approach #1: Careful selection of noise
</h3>

Typically, a reconstruction algorithm is presented
with white Gaussian noise (WGN) added to the data. One
technique to perform the happy transform is to
carefully select the noise.
In this case, we simulated a homogenous (v<sub>h</sub>)
and inhomogeneous (v<sub>i</sub>) data on a 256
element FEM. Subsequently 17.75dB of WGN was added to
v<sub>i</sub>, and the images reconstructed using
the algorithm of 
<a href="http://cvs.sourceforge.net/viewcvs.py/eidors3d/eidors3d/algorithms/aa_1996/">Adler and Guardo (1996)</a>.
Each image was reconstructed (with different selections of
hyperparameter values), and reviewed by the author to determine which cases
corresponded to the happy transform.

<pre>% Test image for different noise
% $Id: tutorial210c.m 3848 2013-04-16 16:55:57Z aadler $

il_g= mk_common_model('c2c2',16);

num_tries=6; clear vi_n;
for i= 1:num_tries 
   vi_n(:,i) = add_noise(2, vi, vh);
end

img = inv_solve( il_g, vh, vi_n );
img.calc_colours.greylev = .01;
img.show_slices.img_cols = num_tries;
show_slices( img );
</pre>

 Fig. 2 shows two successful 'happy' images.
<center>
<img height="128" src="tutorial210-happynoise.png" >
<br>
<b>Fig. 2:</b>
Images with 17.75dB WGN which were selected as 'happy'
</center><p>

In order to determine the frequency of 'happy' noise, 2000
images were reviewed and 41 were selected, corresponding
to an occurance rate of approximately 2%.

While careful noise selection is not a mathematical/computational
technique, it is commonly used in association in research,
and thus merits mention here.

<h3>
Approach #2: Careful selection of priors
</h3>

The Bayesian framework for regularization interprets
the image penalty term as <i>a priori</i> information 
about the underlying image probability distribution.
In practice, however, this term is selected using
ad hoc or heuristic techniques. If the prior does
not correspond to the real case, then the reconstructed
image will be biased. This idea is key for approach #2.
<p>
In a Tikhonov regularization scheme, image amplitude
is penalized. We use the following formulation:
<center>
   <b>x</b> = (<b>H</b><sup>t</sup><b>H</b> +
                &lambda;<b>R</b>)<sup>&minus;1</sup>
               <b>H</b><sup>t</sup><b>y</b>
</center>
where the regularization term 
<center>
<b>R</b> = &radic;( trace <b>H</b><sup>t</sup><b>H</b> )
</center>

If, however, we <u>know</u> <i>a priori</i> that 
our data were measured from a happy face, then we 
would not wish to penalize image pixels which we
<u>know</u> to be large. Thus for each pixel <i>i</i>
in the happy face, we set 
<center>
<b>R</b><sub><i>i</i>,<i>i</i></sub> =
   &frac12; &radic;( trace <b>H</b><sup>t</sup><b>H</b>
                   )<sub><i>i</i>,<i>i</i></sub>
</center>

In order to implement this prior function with
EIDORS, we define function
<tt>tutorial210_cheat_tikhonov.m</tt> as follows
<pre>function Reg= tutorial210_cheat_tikhonov( inv_model )
% Reg= cheat_tikhonov( inv_model )
% Reg        => output regularization term
% Parameters:
%   elems    = inv_model.RtR_prior.cheat_elements;
%            => elements weights to modify
%   weight   = inv_model.RtR_prior.cheat_weight;
%            => new weight to set elements to


pp= fwd_model_parameters( inv_model.fwd_model );
idx= 1:pp.n_elem;
weight= ones(1,pp.n_elem);
weight( inv_model.tutorial210_cheat_tikhonov.cheat_elements ) = ...
        inv_model.tutorial210_cheat_tikhonov.cheat_weight;

Reg = sparse( idx, idx, weight );
</pre>

Images are reconstructed with this prior as follows:
<pre>% Reconstruct images with cheating Tikhonov prior (large model)
% $Id: tutorial210e.m 2674 2011-07-13 07:21:17Z bgrychtol $

lmdl= mk_common_model('c2c');
lmdl.RtR_prior= @tutorial210_cheat_tikhonov;
lmdl.tutorial210_cheat_tikhonov.cheat_weight= .5;
clear im_st;

% Normal Tikhonov prior
lmdl.tutorial210_cheat_tikhonov.cheat_elements= [];
im_st(1)= inv_solve(lmdl, vh, vi);

% Normal Tikhonov with sad face
lmdl.tutorial210_cheat_tikhonov.cheat_elements=  ...
     large_face.sad;
im_st(2)= inv_solve(lmdl, vh, vi);

% Normal Tikhonov with halarge_facey face
lmdl.tutorial210_cheat_tikhonov.cheat_elements=  ...
     large_face.happy;
im_st(3)= inv_solve(lmdl, vh, vi);

% Normal Tikhonov with half face
lmdl.tutorial210_cheat_tikhonov.cheat_elements=  ...
     large_face.halfy;
im_st(4)= inv_solve(lmdl, vh, vi);
im_st(1).calc_colours.greylev = .01;
im_st(1).show_slices.img_cols = 4;
show_slices( im_st);
</pre>

The effect of careful prior selection is hown in Fig. 3.
In this case, images were reconstructed on a 576 element
FEM (chosen to differ from the 256 element simulation mesh).

<center>
<img height="128" src="tutorial210e.png" >
<br>
<b>Fig. 3:</b>
Reconstructed images illustrating the effect of image priors,
using <i>different</i> mesh for model and reconstruction.
Images are numbered from left to right.
<i>Image 1:</i> Tikhonov prior with no weighting,
<i>Image 2:</i> Tikhonov prior with weighting for positions in sad face,
<i>Image 3:</i> Tikhonov prior with weighting for sad face (left) and
happy face (right),
<i>Image 4:</i> Tikhonov prior with weighting for positions in happy face,
</center><p>

<p>
In order to enhance this effect, we use an <i>inverse crime</i>,
by putting the Tikhonov prior information <i>exactly</i> where
it needs to be to get the happy face (Fig. 4).
Images are reconstructed with this prior as follows:
<pre>% Reconstruct images with cheating Tikhonov prior (small model)
% $Id: tutorial210d.m 2647 2011-07-12 08:33:48Z bgrychtol $

smdl= mk_common_model('b2c');
smdl.RtR_prior= @tutorial210_cheat_tikhonov;
smdl.tutorial210_cheat_tikhonov.cheat_weight= .5;

% Normal Tikhonov prior
smdl.tutorial210_cheat_tikhonov.cheat_elements= [];
im_st(1)= inv_solve(smdl, vh, vi);

% Normal Tikhonov with sad face
smdl.tutorial210_cheat_tikhonov.cheat_elements=  ...
    [small_face.eyes, small_face.sad];
im_st(2)= inv_solve(smdl, vh, vi);

% Normal Tikhonov with hasmall_facey face
smdl.tutorial210_cheat_tikhonov.cheat_elements=  ...
    [small_face.eyes, small_face.smile];
im_st(3)= inv_solve(smdl, vh, vi);

% Normal Tikhonov with half face
smdl.tutorial210_cheat_tikhonov.cheat_elements=  ...
    [small_face.eyes, small_face.rsmile, small_face.lsad];
im_st(4)= inv_solve(smdl, vh, vi);
im_st(1).calc_colours.greylev = .01;
im_st(1).show_slices.img_cols = 4;
show_slices( im_st);
</pre>

<center>
<img height="128" src="tutorial210d.png" >
<br>
<b>Fig. 4:</b>
Reconstructed images illustrating the effect of image priors,
using <i>same</i> mesh for model and reconstruction.
Images are numbered from left to right.
<i>Image 1:</i> Tikhonov prior with no weighting,
<i>Image 2:</i> Tikhonov prior with weighting for positions in sad face,
<i>Image 3:</i> Tikhonov prior with weighting for sad face (left) and
happy face (right),
<i>Image 4:</i> Tikhonov prior with weighting for positions in happy face,
</center><p>

<h3>
Approach #3: Edge based priors
</h3>

It is somewhat difficult to properly model a Laplacian filter
on a Finite Element mesh, but one way to approximate it is to
do the following: for each edge between elements <i>i</i>
and <i>j</i>, put 1 at <i>i</i>,<i>i</i> and <i>j</i>,<i>j</i>
and &minus;1 at <i>i</i>,<i>j</i> and <i>j</i>,<i>i</i>.

<p>
Such a Laplacian filter can be used as a regularization prior
to penalize high frequency components (edges) in the image.
On the other hand, if we <i>know</i> where the edges are,
then edges should not be penalized (or be less penalized) in
those places.
<p>
In order to implement this prior function with
EIDORS, we define function
<tt>tutorial210_cheat_laplace.m</tt> as follows. 
This function is clearly more complicated than the
<tt>tutorial210_cheat_tikhonov.m</tt> because we
need to search for adjoining elements in the FEM.

<pre>function Reg= tutorial210_cheat_laplace( inv_model )
% Reg= cheat_laplace( inv_model )
% Reg        => output regularization term
% Parameters:
%   elems    = inv_model.tutorial210_cheat_laplace.cheat_elements;
%            => elements weights to modify
%   weight   = inv_model.tutorial210_cheat_laplace.cheat_weight;
%            => new weight to set elements to

pp= fwd_model_parameters( inv_model.fwd_model );

ROI = zeros(1,pp.n_elem);
ROI( inv_model.tutorial210_cheat_laplace.cheat_elements ) = 1;

Iidx= [];
Jidx= [];
Vidx= [];
for ii=1:pp.n_elem
  el_adj = find_adjoin( ii, pp.ELEM );
  for jj=el_adj(:)'
      if (ROI(ii) + ROI(jj)) == 1 %one only
         fac= inv_model.tutorial210_cheat_laplace.cheat_weight *.5;
      else 
         fac = .5;
      end
      Iidx= [Iidx,      ii, ii, jj, jj];
      Jidx= [Jidx,      ii, jj, ii, jj];
      Vidx= [Vidx, fac*([1, -1, -1,  1]) ];
  end
end
Reg = sparse(Iidx,Jidx, Vidx, pp.n_elem, pp.n_elem );

% find elems which are connected to elems ee
function elems= find_adjoin(ee, ELEM)
   nn= ELEM(:,ee);
   [d,e]= size(ELEM);
   ss= zeros(1,e);
   for i=1:d
     ss= ss+ any(ELEM==nn(i));
   end
   elems= find(ss==d-1);
</pre>
Images are reconstructed with this prior as follows (using
almost identical code to the previous example):
<pre>% Reconstruct images with cheating Laplace prior (large model)
% $Id: tutorial210g.m 2674 2011-07-13 07:21:17Z bgrychtol $

lmdl= mk_common_model('c2c');
lmdl.RtR_prior= @tutorial210_cheat_laplace;
lmdl.tutorial210_cheat_laplace.cheat_weight= .3;
clear im_st;

% Normal Tikhonov prior
lmdl.tutorial210_cheat_laplace.cheat_elements= [];
im_st(1)= inv_solve(lmdl, vh, vi);

% Normal Tikhonov with sad face
lmdl.tutorial210_cheat_laplace.cheat_elements=  ...
     large_face.sad;
im_st(2)= inv_solve(lmdl, vh, vi);

% Normal Tikhonov with halarge_facey face
lmdl.tutorial210_cheat_laplace.cheat_elements=  ...
     large_face.happy;
im_st(3)= inv_solve(lmdl, vh, vi);

% Normal Tikhonov with half face
lmdl.tutorial210_cheat_laplace.cheat_elements=  ...
     large_face.halfy;
im_st(4)= inv_solve(lmdl, vh, vi);
im_st(1).calc_colours.greylev = .01;
im_st(1).show_slices.img_cols = 4;
show_slices( im_st);
</pre>

 Fig 5 shows the effect of such careful
edge preserving prior selection (with no <i>inverse crime</i>).
<i>Known edges</i> are weighted at 0.3&times;that of other
edges in the image.

<center>
<img height="128" src="tutorial210g-laplace3.png" >
<br>
<b>Fig. 5:</b>
Reconstructed images illustrating the effect of edge
preserving image priors,
using <i>different</i> mesh for model and reconstruction.
Images are numbered from left to right.
<i>Known edges</i> are weighted at 0.3&times;that of other
edges in the image.
<i>Image 1:</i> Edge prior with no weighting,
<i>Image 2:</i> Edge prior with weighting for positions in sad face,
<i>Image 3:</i> Edge prior with weighting for sad face (left) and
happy face (right),
<i>Image 4:</i> Edge prior with weighting for positions in happy face,
</center><p>

<p>
In order to enhance this effect, we use an <i>inverse crime</i>,
by putting the Tikhonov prior information <i>exactly</i> where
it needs to be to get the happy face (Fig. 6).
<i>Known edges</i> are weighted at 0.3&times;that of other
edges in the image.
Images are reconstructed with this prior as follows:
<pre>% Reconstruct images with cheating Laplace prior (small model)
% $Id: tutorial210f.m 2674 2011-07-13 07:21:17Z bgrychtol $

smdl= mk_common_model('b2c');
smdl.RtR_prior= @tutorial210_cheat_laplace;
smdl.tutorial210_cheat_laplace.cheat_weight= .3;
clear im_st;

% Normal Tikhonov prior
smdl.tutorial210_cheat_laplace.cheat_elements= [];
im_st(1)= inv_solve(smdl, vh, vi);

% Normal Tikhonov with sad face
smdl.tutorial210_cheat_laplace.cheat_elements=  ...
    [small_face.eyes, small_face.sad];
im_st(2)= inv_solve(smdl, vh, vi);

% Normal Tikhonov with hasmall_facey face
smdl.tutorial210_cheat_laplace.cheat_elements=  ...
    [small_face.eyes, small_face.smile];
im_st(3)= inv_solve(smdl, vh, vi);

% Normal Tikhonov with half face
smdl.tutorial210_cheat_laplace.cheat_elements=  ...
    [small_face.eyes, small_face.rsmile, small_face.lsad];
im_st(4)= inv_solve(smdl, vh, vi);
im_st(1).calc_colours.greylev = .01;
im_st(1).show_slices.img_cols = 4;
show_slices( im_st);
</pre>


<center>
<img height="128" src="tutorial210f-laplace3-icrime.png" >
<br>
<b>Fig. 6:</b>
Reconstructed images illustrating the effect of edge
preserving image priors,
using <i>same</i> mesh for model and reconstruction.
Images are numbered from left to right.
<i>Known edges</i> are weighted at 0.3&times;that of other
edges in the image.
<i>Image 1:</i> Edge prior with no weighting,
<i>Image 2:</i> Edge prior with weighting for positions in sad face,
<i>Image 3:</i> Edge prior with weighting for sad face (left) and
happy face (right),
<i>Image 4:</i> Edge prior with weighting for positions in happy face,
</center><p>
<p>
An even more dramatic effect is obtained by setting the
penalty for <i>Known edges</i> to be zero (Fig. 7).

<center>
<img height="128" src="tutorial210f-laplace0-icrime.png" >
<br>
<b>Fig. 7:</b>
Reconstructed images illustrating the effect of edge
preserving image priors,
using <i>same</i> mesh for model and reconstruction.
Images are numbered from left to right.
<i>Known edges</i> are weighted at 0.0&times;that of other
edges in the image.
<i>Image 1:</i> Edge prior with no weighting,
<i>Image 2:</i> Edge prior with weighting for positions in sad face,
<i>Image 3:</i> Edge prior with weighting for sad face (left) and
happy face (right),
<i>Image 4:</i> Edge prior with weighting for positions in happy face,
</center><p>


<!--

<h3>
Approach #4: Model mismatches
</h3>

Mismatches between measured (or simulated) data and the
reconstruction model can be an excellent way to introduce
artefacts into the reconstructed images. Perhaps the
most common occurance in EIT is when electrode positions
are not exactly where they were in the model.
<p>
In order to simulate this effect, the geometry of
the simulation model (based on 256 elements) was randomly
deformed in the radial direction based on the three low
order harmonics of the angle. Fig. 8 shows an example
of this effect.

The electrodes are positioned at a radial distance of 1.0
and underwent an average movement of 0.091&plusmn;0.035.
<center>
<img src="deform-grille.png" >
<br>
<b>Fig. 8:</b>
A finite element mesh deformed in the radial direction to
simulate the effect of model errors for electrode positions.
</center><p>

Simulations of model error were conducted and evaluated as
to whether they implemented the happy transform, as shown
in Fig. 9. Of 400 images, approximate 1% showed this effect. 

<center>
<img src="deform.png" height="128">
<br>
<b>Fig. 9:</b>
Sample images reconstucted from a deformed finite element
mesh. Some images were chosen which implement the happy
transform, while others were chosen because they appeared
humerous.
</center><p>
-->
<h3>
Conclusion
</h3>

The goal of this document is to illustrate some of the things
that can go wrong with the algorithms provided with EIDORS.
While the treatment in this document is lighthearted, it
is surprisingly easy to unwittingly develop mathematical
algorithms which are subject to variants of these <i>cheats</i>.
We hope that these ideas will help clarify the kinds of
possible errors, and help researchers to avoid them.


</Body></html>
